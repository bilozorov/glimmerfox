{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Testing Postgres"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import uuid\n",
    "import psycopg2\n",
    "from psycopg2 import OperationalError, DatabaseError\n",
    "from psycopg2.extras import DictCursor\n",
    "from datetime import datetime, timezone, timedelta\n",
    "from zoneinfo import ZoneInfo\n",
    "from dotenv import load_dotenv\n",
    "import random\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "is_localhost = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "if is_localhost:\n",
    "    load_dotenv('../.env')\n",
    "else:\n",
    "    load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'glimmerfox_db'"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.environ['POSTGRES_DB']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ['RUN_TIMEZONE_CHECK'] = '0'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "zoneinfo.ZoneInfo(key='Europe/Berlin')"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "RUN_TIMEZONE_CHECK = os.getenv('RUN_TIMEZONE_CHECK', '1') == '1'\n",
    "\n",
    "TZ_INFO = os.getenv(\"TZ\", \"Europe/Berlin\")\n",
    "tz = ZoneInfo(TZ_INFO)\n",
    "tz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_db_connection(localhost=False):\n",
    "\n",
    "    if localhost:\n",
    "        host=os.getenv(\"POSTGRES_HOST_LOCAL\", \"localhost\")\n",
    "    else:\n",
    "        host=os.getenv(\"POSTGRES_HOST\", \"postgres\")\n",
    "    try:\n",
    "        connection = psycopg2.connect(\n",
    "            host=host,\n",
    "            database=os.getenv(\"POSTGRES_DB\", \"glimmerfox_db\"),\n",
    "            user=os.getenv(\"POSTGRES_USER\", \"your_username\"),\n",
    "            password=os.getenv(\"POSTGRES_PASSWORD\", \"your_password\"),\n",
    "        )\n",
    "        return connection\n",
    "    except OperationalError as e:\n",
    "        print(f\"Error: Could not connect to the PostgreSQL database.\\nDetails: {e}\")\n",
    "        return None\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "def init_db(localhost=False):\n",
    "    conn = get_db_connection(localhost=localhost)\n",
    "    if conn is None:\n",
    "        print(\"Database connection failed.\")\n",
    "        return  # Exit the function if the connection failed\n",
    "\n",
    "    try:\n",
    "        with conn.cursor() as cur:\n",
    "            cur.execute(\"DROP TABLE IF EXISTS feedback\")\n",
    "            cur.execute(\"DROP TABLE IF EXISTS queries\")\n",
    "\n",
    "            cur.execute(\"\"\"\n",
    "                CREATE TABLE queries (\n",
    "                    id TEXT PRIMARY KEY,\n",
    "                    question TEXT NOT NULL,\n",
    "                    answer TEXT NOT NULL,\n",
    "                    model_used TEXT NOT NULL,\n",
    "                    response_time FLOAT NOT NULL,\n",
    "                    relevance TEXT NOT NULL,\n",
    "                    relevance_explanation TEXT NOT NULL,\n",
    "                    input_tokens INTEGER NOT NULL,\n",
    "                    output_tokens INTEGER NOT NULL,\n",
    "                    total_tokens INTEGER NOT NULL,\n",
    "                    eval_input_tokens INTEGER NOT NULL,\n",
    "                    eval_output_tokens INTEGER NOT NULL,\n",
    "                    eval_total_tokens INTEGER NOT NULL,\n",
    "                    openai_cost FLOAT NOT NULL,\n",
    "                    timestamp TIMESTAMP WITH TIME ZONE NOT NULL\n",
    "                )\n",
    "            \"\"\")\n",
    "            print(\"Table 'queries' created successfully.\")\n",
    "\n",
    "            # Create 'feedback' table\n",
    "            cur.execute(\"\"\"\n",
    "                CREATE TABLE feedback (\n",
    "                    id SERIAL PRIMARY KEY,\n",
    "                    query_id TEXT REFERENCES queries(id),\n",
    "                    feedback INTEGER NOT NULL,\n",
    "                    timestamp TIMESTAMP WITH TIME ZONE NOT NULL\n",
    "                )\n",
    "            \"\"\")\n",
    "            print(\"Table 'feedback' created successfully.\")\n",
    "\n",
    "        # Commit the changes\n",
    "        conn.commit()\n",
    "        print(\"Database initialization completed successfully.\")\n",
    "\n",
    "        # Verify table creation by querying information_schema\n",
    "        with conn.cursor() as cur:\n",
    "            cur.execute(\"\"\"\n",
    "                SELECT table_name FROM information_schema.tables \n",
    "                WHERE table_schema = 'public'\n",
    "            \"\"\")\n",
    "            tables = cur.fetchall()\n",
    "            print(\"Tables in the database:\", tables)\n",
    "\n",
    "    except DatabaseError as e:\n",
    "        print(f\"Database error: {e}\")\n",
    "        conn.rollback()  # Rollback in case of error\n",
    "\n",
    "    finally:\n",
    "        # Ensure the connection is always closed\n",
    "        if conn:\n",
    "            conn.close()\n",
    "            print(\"Database connection closed.\")\n",
    "\n",
    "        conn.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_query(query_id, question, answer_data, timestamp=None, localhost=False):\n",
    "    # change save_conversation -> save_query\n",
    "\n",
    "    if timestamp is None:\n",
    "        timestamp = datetime.now(tz)\n",
    "\n",
    "    conn = get_db_connection(localhost=localhost)\n",
    "    try:\n",
    "        with conn.cursor() as cur:\n",
    "            cur.execute(\n",
    "                \"\"\"\n",
    "                INSERT INTO queries \n",
    "                (id, question, answer, model_used, response_time, relevance, \n",
    "                relevance_explanation, input_tokens, output_tokens, total_tokens, \n",
    "                eval_input_tokens, eval_output_tokens, eval_total_tokens, openai_cost, timestamp)\n",
    "                VALUES (%s, %s, %s, %s, %s, %s, %s, %s, %s, %s, %s, %s, %s, %s, %s)\n",
    "                \"\"\",\n",
    "                (\n",
    "                    query_id,\n",
    "                    question,\n",
    "                    answer_data[\"answer\"],\n",
    "                    answer_data[\"model_used\"],\n",
    "                    answer_data[\"response_time\"],\n",
    "                    answer_data[\"relevance\"],\n",
    "                    answer_data[\"relevance_explanation\"],\n",
    "                    answer_data[\"input_tokens\"],\n",
    "                    answer_data[\"output_tokens\"],\n",
    "                    answer_data[\"total_tokens\"],\n",
    "                    answer_data[\"eval_input_tokens\"],\n",
    "                    answer_data[\"eval_output_tokens\"],\n",
    "                    answer_data[\"eval_total_tokens\"],\n",
    "                    answer_data[\"openai_cost\"],\n",
    "                    timestamp\n",
    "                ),\n",
    "            )\n",
    "        conn.commit()\n",
    "    finally:\n",
    "        conn.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_feedback(query_id, feedback, timestamp=None, localhost=False):\n",
    "    if timestamp is None:\n",
    "        timestamp = datetime.now(tz)\n",
    "\n",
    "    conn = get_db_connection(localhost=localhost)\n",
    "    try:\n",
    "        with conn.cursor() as cur:\n",
    "            cur.execute(\n",
    "                \"INSERT INTO feedback (query_id, feedback, timestamp) VALUES (%s, %s, COALESCE(%s, CURRENT_TIMESTAMP))\",\n",
    "                (query_id, feedback, timestamp),\n",
    "            )\n",
    "        conn.commit()\n",
    "    finally:\n",
    "        conn.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clear_tables(localhost=False):\n",
    "    conn = get_db_connection(localhost=localhost)\n",
    "    if conn is None:\n",
    "        print(\"Database connection failed.\")\n",
    "        return\n",
    "\n",
    "    try:\n",
    "        with conn.cursor() as cur:\n",
    "            cur.execute(\"DELETE FROM feedback\")  # Clear the 'feedback' table first due to foreign key constraint\n",
    "            cur.execute(\"DELETE FROM queries\")   # Then clear the 'queries' table\n",
    "        conn.commit()\n",
    "        print(\"All entries in 'queries' and 'feedback' tables have been deleted.\")\n",
    "    except psycopg2.DatabaseError as e:\n",
    "        print(f\"Error deleting records from tables: {e}\")\n",
    "        conn.rollback()\n",
    "    finally:\n",
    "        if conn:\n",
    "            conn.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_openai_cost(model_choice, tokens):\n",
    "    openai_cost = 0\n",
    "\n",
    "    if model_choice in ['openai/gpt-4o', 'openai/gpt-4o-mini']:\n",
    "        openai_cost = (tokens['input_tokens'] * 0.000150 + tokens['output_tokens'] * 0.000600) / 1000\n",
    "\n",
    "    return openai_cost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Function to generate sample queries\n",
    "# def generate_sample_queries(n):\n",
    "#     sample_queries = []\n",
    "#     for i in range(n):\n",
    "#         query_id = str(uuid.uuid4())\n",
    "#         question = f\"What is the meaning of life {i}?\"\n",
    "#         input_tokens = random.randint(234, 567)\n",
    "#         output_tokens = random.randint(234, 567)\n",
    "#         total_tokens = input_tokens + output_tokens\n",
    "#         eval_input_tokens = random.randint(234, 567)\n",
    "#         eval_output_tokens = random.randint(234, 567)\n",
    "#         eval_total_tokens = eval_input_tokens + eval_output_tokens\n",
    "\n",
    "#         answer_data = {\n",
    "#             \"answer\": f\"The meaning of life {i} is subjective.\",\n",
    "#             \"model_used\": \"gpt-4o-mini\",\n",
    "#             \"response_time\": round(random.uniform(0.5, 2.5), 2),  # Random response time between 0.5 and 2.5 seconds\n",
    "#             \"relevance\": random.choice([\"NON_RELEVANT\", \"PARTLY_RELEVANT\", \"RELEVANT\"]),\n",
    "#             \"relevance_explanation\": f\"The answer is {random.choice(['very', 'somewhat', 'not'])} relevant to the question.\",\n",
    "#             \"input_tokens\": input_tokens,  # Random token count between 10 and 50\n",
    "#             \"output_tokens\": output_tokens,  # Random token count between 10 and 50\n",
    "#             \"total_tokens\": total_tokens,  # Random total tokens\n",
    "#             \"eval_input_tokens\": eval_input_tokens,  # Random token count for evaluation prompt\n",
    "#             \"eval_output_tokens\": eval_output_tokens,  # Random token count for evaluation completion\n",
    "#             \"eval_total_tokens\": eval_total_tokens,  # Random evaluation total tokens\n",
    "#             # \"openai_cost\": round(random.uniform(0.01, 0.1), 4)  # Random cost between 0.01 and 0.1\n",
    "#             \"openai_cost\": calculate_openai_cost(model_choice='openai/gpt-4o-mini', tokens={'input_tokens': input_tokens+eval_input_tokens, 'output_tokens': output_tokens+eval_output_tokens})\n",
    "#         }\n",
    "#         sample_queries.append((query_id, question, answer_data))\n",
    "#     return sample_queries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to generate sample queries\n",
    "def generate_one_sample_query():\n",
    "    query_id = str(uuid.uuid4())\n",
    "    fake_number = datetime.now().timestamp()\n",
    "    question = f\"What is the meaning of life {fake_number}?\"\n",
    "    input_tokens = random.randint(234, 567)\n",
    "    output_tokens = random.randint(234, 567)\n",
    "    total_tokens = input_tokens + output_tokens\n",
    "    eval_input_tokens = random.randint(234, 567)\n",
    "    eval_output_tokens = random.randint(234, 567)\n",
    "    eval_total_tokens = eval_input_tokens + eval_output_tokens\n",
    "\n",
    "    answer_data = {\n",
    "        \"answer\": f\"The meaning of life {fake_number} is subjective.\",\n",
    "        \"model_used\": \"gpt-4o-mini\",\n",
    "        \"response_time\": round(random.uniform(0.5, 2.5), 2),  # Random response time between 0.5 and 2.5 seconds\n",
    "        # \"relevance\": random.choice([\"NON_RELEVANT\", \"PARTLY_RELEVANT\", \"RELEVANT\"]),\n",
    "        \"relevance\": random.choices([\"NON_RELEVANT\", \"PARTLY_RELEVANT\", \"RELEVANT\"], weights=[1, 2, 4], k=1)[0],\n",
    "        \"relevance_explanation\": f\"The answer is {random.choice(['very', 'somewhat', 'not'])} relevant to the question.\",\n",
    "        \"input_tokens\": input_tokens,  # Random token count between 10 and 50\n",
    "        \"output_tokens\": output_tokens,  # Random token count between 10 and 50\n",
    "        \"total_tokens\": total_tokens,  # Random total tokens\n",
    "        \"eval_input_tokens\": eval_input_tokens,  # Random token count for evaluation prompt\n",
    "        \"eval_output_tokens\": eval_output_tokens,  # Random token count for evaluation completion\n",
    "        \"eval_total_tokens\": eval_total_tokens,  # Random evaluation total tokens\n",
    "        # \"openai_cost\": round(random.uniform(0.01, 0.1), 4)  # Random cost between 0.01 and 0.1\n",
    "        \"openai_cost\": calculate_openai_cost(model_choice='openai/gpt-4o-mini', tokens={'input_tokens': input_tokens+eval_input_tokens, 'output_tokens': output_tokens+eval_output_tokens})\n",
    "    }\n",
    "    return (query_id, question, answer_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def get_recent_conversations(limit=5, relevance=None):\n",
    "#     conn = get_db_connection()\n",
    "#     try:\n",
    "#         with conn.cursor(cursor_factory=DictCursor) as cur:\n",
    "#             query = \"\"\"\n",
    "#                 SELECT c.*, f.feedback\n",
    "#                 FROM queries c\n",
    "#                 LEFT JOIN feedback f ON c.id = f.query_id\n",
    "#             \"\"\"\n",
    "#             if relevance:\n",
    "#                 query += f\" WHERE c.relevance = '{relevance}'\"\n",
    "#             query += \" ORDER BY c.timestamp DESC LIMIT %s\"\n",
    "\n",
    "#             cur.execute(query, (limit,))\n",
    "#             return cur.fetchall()\n",
    "#     finally:\n",
    "#         conn.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def get_feedback_stats():\n",
    "#     conn = get_db_connection()\n",
    "#     try:\n",
    "#         with conn.cursor(cursor_factory=DictCursor) as cur:\n",
    "#             cur.execute(\"\"\"\n",
    "#                 SELECT \n",
    "#                     SUM(CASE WHEN feedback > 0 THEN 1 ELSE 0 END) as thumbs_up,\n",
    "#                     SUM(CASE WHEN feedback < 0 THEN 1 ELSE 0 END) as thumbs_down\n",
    "#                 FROM feedback\n",
    "#             \"\"\")\n",
    "#             return cur.fetchone()\n",
    "#     finally:\n",
    "#         conn.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def check_timezone():\n",
    "#     conn = get_db_connection()\n",
    "#     try:\n",
    "#         with conn.cursor() as cur:\n",
    "#             cur.execute(\"SHOW timezone;\")\n",
    "#             db_timezone = cur.fetchone()[0]\n",
    "#             print(f\"Database timezone: {db_timezone}\")\n",
    "\n",
    "#             cur.execute(\"SELECT current_timestamp;\")\n",
    "#             db_time_utc = cur.fetchone()[0]\n",
    "#             print(f\"Database current time (UTC): {db_time_utc}\")\n",
    "\n",
    "#             db_time_local = db_time_utc.astimezone(tz)\n",
    "#             print(f\"Database current time ({TZ_INFO}): {db_time_local}\")\n",
    "\n",
    "#             py_time = datetime.now(tz)\n",
    "#             print(f\"Python current time: {py_time}\")\n",
    "\n",
    "#             # Use py_time instead of tz for insertion\n",
    "#             cur.execute(\"\"\"\n",
    "#                 INSERT INTO queries \n",
    "#                 (id, question, answer, model_used, response_time, relevance, \n",
    "#                 relevance_explanation, input_tokens, output_tokens, total_tokens, \n",
    "#                 eval_input_tokens, eval_output_tokens, eval_total_tokens, openai_cost, timestamp)\n",
    "#                 VALUES (%s, %s, %s, %s, %s, %s, %s, %s, %s, %s, %s, %s, %s, %s, %s)\n",
    "#                 RETURNING timestamp;\n",
    "#             \"\"\", \n",
    "#             ('test', 'test question', 'test answer', 'test model', 0.0, 0.0, \n",
    "#              'test explanation', 0, 0, 0, 0, 0, 0, 0.0, py_time))\n",
    "\n",
    "#             inserted_time = cur.fetchone()[0]\n",
    "#             print(f\"Inserted time (UTC): {inserted_time}\")\n",
    "#             print(f\"Inserted time ({TZ_INFO}): {inserted_time.astimezone(tz)}\")\n",
    "\n",
    "#             cur.execute(\"SELECT timestamp FROM conversations WHERE id = 'test';\")\n",
    "#             selected_time = cur.fetchone()[0]\n",
    "#             print(f\"Selected time (UTC): {selected_time}\")\n",
    "#             print(f\"Selected time ({TZ_INFO}): {selected_time.astimezone(tz)}\")\n",
    "\n",
    "#             # Clean up the test entry\n",
    "#             cur.execute(\"DELETE FROM conversations WHERE id = 'test';\")\n",
    "#             conn.commit()\n",
    "#     except Exception as e:\n",
    "#         print(f\"An error occurred: {e}\")\n",
    "#         conn.rollback()\n",
    "#     finally:\n",
    "#         conn.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# RUN_TIMEZONE_CHECK"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "# if RUN_TIMEZONE_CHECK:\n",
    "#     check_timezone()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prepare DB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<connection object at 0x1177e46d0; dsn: 'user=your_username password=xxx dbname=glimmerfox_db host=localhost', closed: 0>"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_db_connection(localhost=is_localhost)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Table 'queries' created successfully.\n",
      "Table 'feedback' created successfully.\n",
      "Database initialization completed successfully.\n",
      "Tables in the database: [('queries',), ('feedback',)]\n",
      "Database connection closed.\n"
     ]
    }
   ],
   "source": [
    "init_db(localhost=is_localhost)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All entries in 'queries' and 'feedback' tables have been deleted.\n"
     ]
    }
   ],
   "source": [
    "clear_tables(localhost=is_localhost)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Generating historical data for 6 hours"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def generate_synthetic_data_old(start_time, end_time):\n",
    "#     # clear_tables(localhost=is_localhost)\n",
    "#     sample_queries = generate_sample_queries(20)\n",
    "\n",
    "#     for query_id, question, answer_data in sample_queries:\n",
    "#         save_query(query_id, question, answer_data)\n",
    "#         save_feedback(\n",
    "#             query_id=query_id, \n",
    "#             feedback=int(random.choice([True, False]))\n",
    "#             )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_synthetic_data(start_time, end_time, localhost=False):\n",
    "    current_time = start_time\n",
    "    queries_count = 0\n",
    "    print(f\"Starting historical data generation from {start_time} to {end_time}\")\n",
    "    while current_time < end_time:\n",
    "\n",
    "        query_id, question, answer_data = generate_one_sample_query()\n",
    "        \n",
    "        save_query(query_id, question, answer_data, current_time, localhost=localhost)\n",
    "        # print(\n",
    "        #     f\"Saved query: ID={query_id}, Time={current_time}\"\n",
    "        # )\n",
    "\n",
    "        if random.random() < 0.7:\n",
    "            feedback = 1 if random.random() < 0.8 else -1\n",
    "            save_feedback(\n",
    "                query_id=query_id, \n",
    "                feedback=int(random.choice([True, False])), \n",
    "                timestamp=current_time, \n",
    "                localhost=True)\n",
    "            # print(\n",
    "            #     f\"Saved feedback for query {query_id}: {'Positive' if feedback > 0 else 'Negative'}\"\n",
    "            # )\n",
    "\n",
    "        # current_time += timedelta(minutes=random.randint(1, 2))\n",
    "        # current_time += timedelta(minutes=random.randint(1, 2))\n",
    "        current_time += timedelta(seconds=random.randint(1, 20))\n",
    "        queries_count += 1\n",
    "        if queries_count % 10 == 0:\n",
    "            print(f\"Generated {queries_count} queries so far...\")\n",
    "\n",
    "    print(\n",
    "        f\"Historical data generation complete. Total queries: {queries_count}\"\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Script started at 2024-09-14 16:02:13.232191+02:00\n",
      "Generating historical data from 2024-09-14 10:02:13.232300+02:00 to 2024-09-14 16:02:13.232300+02:00\n",
      "Starting historical data generation from 2024-09-14 10:02:13.232300+02:00 to 2024-09-14 16:02:13.232300+02:00\n",
      "Generated 10 queries so far...\n",
      "Generated 20 queries so far...\n",
      "Generated 30 queries so far...\n",
      "Generated 40 queries so far...\n",
      "Generated 50 queries so far...\n",
      "Generated 60 queries so far...\n",
      "Generated 70 queries so far...\n",
      "Generated 80 queries so far...\n",
      "Generated 90 queries so far...\n",
      "Generated 100 queries so far...\n",
      "Generated 110 queries so far...\n",
      "Generated 120 queries so far...\n",
      "Generated 130 queries so far...\n",
      "Generated 140 queries so far...\n",
      "Generated 150 queries so far...\n",
      "Generated 160 queries so far...\n",
      "Generated 170 queries so far...\n",
      "Generated 180 queries so far...\n",
      "Generated 190 queries so far...\n",
      "Generated 200 queries so far...\n",
      "Generated 210 queries so far...\n",
      "Generated 220 queries so far...\n",
      "Generated 230 queries so far...\n",
      "Generated 240 queries so far...\n",
      "Generated 250 queries so far...\n",
      "Generated 260 queries so far...\n",
      "Generated 270 queries so far...\n",
      "Generated 280 queries so far...\n",
      "Generated 290 queries so far...\n",
      "Generated 300 queries so far...\n",
      "Generated 310 queries so far...\n",
      "Generated 320 queries so far...\n",
      "Generated 330 queries so far...\n",
      "Generated 340 queries so far...\n",
      "Generated 350 queries so far...\n",
      "Generated 360 queries so far...\n",
      "Generated 370 queries so far...\n",
      "Generated 380 queries so far...\n",
      "Generated 390 queries so far...\n",
      "Generated 400 queries so far...\n",
      "Generated 410 queries so far...\n",
      "Generated 420 queries so far...\n",
      "Generated 430 queries so far...\n",
      "Generated 440 queries so far...\n",
      "Generated 450 queries so far...\n",
      "Generated 460 queries so far...\n",
      "Generated 470 queries so far...\n",
      "Generated 480 queries so far...\n",
      "Generated 490 queries so far...\n",
      "Generated 500 queries so far...\n",
      "Generated 510 queries so far...\n",
      "Generated 520 queries so far...\n",
      "Generated 530 queries so far...\n",
      "Generated 540 queries so far...\n",
      "Generated 550 queries so far...\n",
      "Generated 560 queries so far...\n",
      "Generated 570 queries so far...\n",
      "Generated 580 queries so far...\n",
      "Generated 590 queries so far...\n",
      "Generated 600 queries so far...\n",
      "Generated 610 queries so far...\n",
      "Generated 620 queries so far...\n",
      "Generated 630 queries so far...\n",
      "Generated 640 queries so far...\n",
      "Generated 650 queries so far...\n",
      "Generated 660 queries so far...\n",
      "Generated 670 queries so far...\n",
      "Generated 680 queries so far...\n",
      "Generated 690 queries so far...\n",
      "Generated 700 queries so far...\n",
      "Generated 710 queries so far...\n",
      "Generated 720 queries so far...\n",
      "Generated 730 queries so far...\n",
      "Generated 740 queries so far...\n",
      "Generated 750 queries so far...\n",
      "Generated 760 queries so far...\n",
      "Generated 770 queries so far...\n",
      "Generated 780 queries so far...\n",
      "Generated 790 queries so far...\n",
      "Generated 800 queries so far...\n",
      "Generated 810 queries so far...\n",
      "Generated 820 queries so far...\n",
      "Generated 830 queries so far...\n",
      "Generated 840 queries so far...\n",
      "Generated 850 queries so far...\n",
      "Generated 860 queries so far...\n",
      "Generated 870 queries so far...\n",
      "Generated 880 queries so far...\n",
      "Generated 890 queries so far...\n",
      "Generated 900 queries so far...\n",
      "Generated 910 queries so far...\n",
      "Generated 920 queries so far...\n",
      "Generated 930 queries so far...\n",
      "Generated 940 queries so far...\n",
      "Generated 950 queries so far...\n",
      "Generated 960 queries so far...\n",
      "Generated 970 queries so far...\n",
      "Generated 980 queries so far...\n",
      "Generated 990 queries so far...\n",
      "Generated 1000 queries so far...\n",
      "Generated 1010 queries so far...\n",
      "Generated 1020 queries so far...\n",
      "Generated 1030 queries so far...\n",
      "Generated 1040 queries so far...\n",
      "Generated 1050 queries so far...\n",
      "Generated 1060 queries so far...\n",
      "Generated 1070 queries so far...\n",
      "Generated 1080 queries so far...\n",
      "Generated 1090 queries so far...\n",
      "Generated 1100 queries so far...\n",
      "Generated 1110 queries so far...\n",
      "Generated 1120 queries so far...\n",
      "Generated 1130 queries so far...\n",
      "Generated 1140 queries so far...\n",
      "Generated 1150 queries so far...\n",
      "Generated 1160 queries so far...\n",
      "Generated 1170 queries so far...\n",
      "Generated 1180 queries so far...\n",
      "Generated 1190 queries so far...\n",
      "Generated 1200 queries so far...\n",
      "Generated 1210 queries so far...\n",
      "Generated 1220 queries so far...\n",
      "Generated 1230 queries so far...\n",
      "Generated 1240 queries so far...\n",
      "Generated 1250 queries so far...\n",
      "Generated 1260 queries so far...\n",
      "Generated 1270 queries so far...\n",
      "Generated 1280 queries so far...\n",
      "Generated 1290 queries so far...\n",
      "Generated 1300 queries so far...\n",
      "Generated 1310 queries so far...\n",
      "Generated 1320 queries so far...\n",
      "Generated 1330 queries so far...\n",
      "Generated 1340 queries so far...\n",
      "Generated 1350 queries so far...\n",
      "Generated 1360 queries so far...\n",
      "Generated 1370 queries so far...\n",
      "Generated 1380 queries so far...\n",
      "Generated 1390 queries so far...\n",
      "Generated 1400 queries so far...\n",
      "Generated 1410 queries so far...\n",
      "Generated 1420 queries so far...\n",
      "Generated 1430 queries so far...\n",
      "Generated 1440 queries so far...\n",
      "Generated 1450 queries so far...\n",
      "Generated 1460 queries so far...\n",
      "Generated 1470 queries so far...\n",
      "Generated 1480 queries so far...\n",
      "Generated 1490 queries so far...\n",
      "Generated 1500 queries so far...\n",
      "Generated 1510 queries so far...\n",
      "Generated 1520 queries so far...\n",
      "Generated 1530 queries so far...\n",
      "Generated 1540 queries so far...\n",
      "Generated 1550 queries so far...\n",
      "Generated 1560 queries so far...\n",
      "Generated 1570 queries so far...\n",
      "Generated 1580 queries so far...\n",
      "Generated 1590 queries so far...\n",
      "Generated 1600 queries so far...\n",
      "Generated 1610 queries so far...\n",
      "Generated 1620 queries so far...\n",
      "Generated 1630 queries so far...\n",
      "Generated 1640 queries so far...\n",
      "Generated 1650 queries so far...\n",
      "Generated 1660 queries so far...\n",
      "Generated 1670 queries so far...\n",
      "Generated 1680 queries so far...\n",
      "Generated 1690 queries so far...\n",
      "Generated 1700 queries so far...\n",
      "Generated 1710 queries so far...\n",
      "Generated 1720 queries so far...\n",
      "Generated 1730 queries so far...\n",
      "Generated 1740 queries so far...\n",
      "Generated 1750 queries so far...\n",
      "Generated 1760 queries so far...\n",
      "Generated 1770 queries so far...\n",
      "Generated 1780 queries so far...\n",
      "Generated 1790 queries so far...\n",
      "Generated 1800 queries so far...\n",
      "Generated 1810 queries so far...\n",
      "Generated 1820 queries so far...\n",
      "Generated 1830 queries so far...\n",
      "Generated 1840 queries so far...\n",
      "Generated 1850 queries so far...\n",
      "Generated 1860 queries so far...\n",
      "Generated 1870 queries so far...\n",
      "Generated 1880 queries so far...\n",
      "Generated 1890 queries so far...\n",
      "Generated 1900 queries so far...\n",
      "Generated 1910 queries so far...\n",
      "Generated 1920 queries so far...\n",
      "Generated 1930 queries so far...\n",
      "Generated 1940 queries so far...\n",
      "Generated 1950 queries so far...\n",
      "Generated 1960 queries so far...\n",
      "Generated 1970 queries so far...\n",
      "Generated 1980 queries so far...\n",
      "Generated 1990 queries so far...\n",
      "Generated 2000 queries so far...\n",
      "Generated 2010 queries so far...\n",
      "Generated 2020 queries so far...\n",
      "Generated 2030 queries so far...\n",
      "Generated 2040 queries so far...\n",
      "Historical data generation complete. Total queries: 2043\n",
      "Historical data generation complete.\n"
     ]
    }
   ],
   "source": [
    "print(f\"Script started at {datetime.now(tz)}\")\n",
    "end_time = datetime.now(tz)\n",
    "start_time = end_time - timedelta(hours=6)\n",
    "print(f\"Generating historical data from {start_time} to {end_time}\")\n",
    "generate_synthetic_data(start_time, end_time, localhost=True)\n",
    "print(\"Historical data generation complete.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Generating historical data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_live_data(localhost=False):\n",
    "    queries_count = 0\n",
    "    print(\"Starting live data generation...\")\n",
    "    while True:\n",
    "        current_time = datetime.now(tz)\n",
    "        # current_time = None\n",
    "        query_id, question, answer_data = generate_one_sample_query()\n",
    "        save_query(query_id, question, answer_data, current_time, localhost=is_localhost)\n",
    "\n",
    "        if random.random() < 0.7:\n",
    "            feedback = 1 if random.random() < 0.8 else -1\n",
    "            save_feedback(\n",
    "                query_id=query_id, \n",
    "                feedback=int(random.choice([True, False])), \n",
    "                timestamp=current_time, \n",
    "                localhost=True)\n",
    "        queries_count += 1\n",
    "        if queries_count % 10 == 0:\n",
    "            print(f\"Generated {queries_count} live queries so far...\")\n",
    "\n",
    "        time.sleep(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting live data generation... Press Ctrl+C to stop.\n",
      "Starting live data generation...\n",
      "Generated 10 live queries so far...\n",
      "Generated 20 live queries so far...\n",
      "Generated 30 live queries so far...\n",
      "Generated 40 live queries so far...\n",
      "Generated 50 live queries so far...\n",
      "Generated 60 live queries so far...\n",
      "Generated 70 live queries so far...\n",
      "Generating historical data stopped at 2024-09-14 15:55:23.416749+02:00.\n",
      "Script ended at 2024-09-14 15:55:23.416850+02:00\n"
     ]
    }
   ],
   "source": [
    "print(\"Starting live data generation... Press Ctrl+C to stop.\")\n",
    "try:\n",
    "    generate_live_data(localhost=is_localhost)\n",
    "except KeyboardInterrupt:\n",
    "    print(f\"Generating historical data stopped at {datetime.now(tz)}.\")\n",
    "finally:\n",
    "    print(f\"Script ended at {datetime.now(tz)}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "glimmerfox",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
